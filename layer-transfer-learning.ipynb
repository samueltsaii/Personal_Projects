{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torchvision.datasets as datasets\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-02T16:57:19.637747Z","iopub.execute_input":"2025-08-02T16:57:19.638435Z","iopub.status.idle":"2025-08-02T16:57:30.554003Z","shell.execute_reply.started":"2025-08-02T16:57:19.638401Z","shell.execute_reply":"2025-08-02T16:57:30.553470Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"Epochs = 10\nbatch_size = 64\nlearning_rate = 1e-4\nl2_regularize = 1e-5\nmomentum = 0.9","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T16:57:30.554671Z","iopub.execute_input":"2025-08-02T16:57:30.554967Z","iopub.status.idle":"2025-08-02T16:57:30.558752Z","shell.execute_reply.started":"2025-08-02T16:57:30.554950Z","shell.execute_reply":"2025-08-02T16:57:30.558028Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_data = datasets.STL10(root = './data', download = True, split = 'train', transform = transform)\ntest_data = datasets.STL10(root = './data', download = True, split = 'test', transform = transform)\n\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\ntest_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T16:57:30.560329Z","iopub.execute_input":"2025-08-02T16:57:30.560936Z"}},"outputs":[{"name":"stderr","text":" 94%|█████████▍| 2.49G/2.64G [01:14<00:03, 42.5MB/s] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model1 = models.efficientnet_v2_l(weights = models.EfficientNet_V2_L_Weights.DEFAULT)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for params in model1.parameters():\n    params.require_grad = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_features = model1.classifier[1].in_features\nmodel1.classifier[1] = nn.Linear(num_features, 10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model1.parameters(), lr=learning_rate, weight_decay=l2_regularize)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model1.classifier)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for _, labels in train_loader:\n    print(\"Label dtype:\", labels.dtype)\n    print(\"Min label:\", labels.min().item())\n    print(\"Max label:\", labels.max().item())\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_losses, test_losses = [], []\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel1.to(device)\n\nfor Epoch in range(Epochs):\n    model1.train()\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model1(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n    train_loss = running_loss / len(train_loader.dataset)\n    train_losses.append(train_loss)\n    \n    model1.eval()\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model1(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * images.size(0)\n    test_loss = running_loss /len(test_loader.dataset)\n    test_losses.append(test_loss)\n        \n    print(f'Epoch {Epoch + 1}/{Epochs} - Train loss: {train_loss}, ')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}